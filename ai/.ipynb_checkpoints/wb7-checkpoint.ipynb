{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354d144a",
   "metadata": {},
   "source": [
    "### 1.1.1 –ü—Ä–∏–º–µ—Ä"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa10f013",
   "metadata": {},
   "source": [
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø—Ä–æ–≥—Ä–∞–º–º—É –æ–±—É—á–µ–Ω–∏—è –ø–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω–∞ –Ω–∞ —è–∑—ã–∫–µ Python. –°–Ω–∞—á–∞–ª–∞  \n",
    "—Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –ø–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω–∞, –∫–æ—Ç–æ—Ä—ã–π —É–º–µ–µ—Ç —É—á–∏—Ç—å—Å—è –ø–æ  \n",
    "—Ç–µ—Å—Ç–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1307deea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, -0.1]\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "# –∫–ª–∞—Å—Å, –∫–æ—Ç–æ—Ä—ã–π —Ä–µ–∞–ª–∏–∑—É–µ—Ç –ø–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω –∏ –µ–≥–æ –æ–±—É—á–µ–Ω–∏–µ\n",
    "class Perceptron:\n",
    "    def __init__(self, N):\n",
    "    # —Å–æ–∑–¥–∞—Ç—å –Ω—É–ª–µ–≤—ã–µ –≤–µ—Å–∞\n",
    "        self.w = list()\n",
    "        for i in range(N):\n",
    "            self.w.append(0)\n",
    "    \n",
    "    # –º–µ—Ç–æ–¥ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∑–Ω–∞—á–µ–Ω–∏—è –ø–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω–∞\n",
    "    def calc(self, x):\n",
    "        res = 0\n",
    "        for i in range(len(self.w)):\n",
    "            res = res + self.w[i] * x[i]\n",
    "        return res\n",
    "    # –ø–æ—Ä–æ–≥–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –ø–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω–∞\n",
    "    def sign(self, x):\n",
    "        if self.calc(x) > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    # –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ\n",
    "    def learn(self, la, x, y):\n",
    "        # –æ–±—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ, –∫–æ–≥–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –Ω–µ–≤–µ—Ä–Ω—ã–π\n",
    "        if y * self.calc(x) <= 0:\n",
    "            for i in range(len(self.w)):\n",
    "                self.w[i] = self.w[i] + la * y * x[i]\n",
    "    # –æ–±—É—á–µ–Ω–∏–µ –ø–æ –≤—Å–µ–º –¥–∞–Ω–Ω—ã–º T - –∫–æ—Ä—Ç–µ–∂ –ø—Ä–∏–º–µ—Ä–æ–≤\n",
    "    def learning(self, la, T):\n",
    "        # —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è\n",
    "        for n in range(100):\n",
    "            # –æ–±—É—á–µ–Ω–∏–µ –ø–æ –≤—Å–µ–º—É –Ω–∞–±–æ—Ä—É –ø—Ä–∏–º–µ—Ä–æ–≤\n",
    "            for t in T:\n",
    "                self.learn(la, t[0], t[1])\n",
    "                \n",
    "\n",
    "# —Å–æ–∑–¥–∞–µ–º –∫–ª–∞—Å—Å –¥–≤—É–º–µ—Ä–Ω–æ–≥–æ –ø–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω–∞\n",
    "perceptron = Perceptron(2)\n",
    "la = 0.1 # –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –æ–±—É—á–µ–Ω–∏—è\n",
    "# —Å–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã\n",
    "T = list()\n",
    "T.append([[2, 1], 1])\n",
    "T.append([[3, 2], 1])\n",
    "T.append([[4, 1], 1])\n",
    "T.append([[1, 2], -1])\n",
    "T.append([[2, 3], -1])\n",
    "T.append([[5, 7], -1])\n",
    "perceptron.learning(la, T) # –æ–±—É—á–µ–Ω–∏–µ –ø–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω–∞\n",
    "print(perceptron.w) # –ø–µ—á–∞—Ç–∞–µ–º –≤–µ—Å–∞\n",
    "# –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–±–æ—Ç—É –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö\n",
    "print(perceptron.sign([1.5, 2]))\n",
    "print(perceptron.sign([3, 1.5]))\n",
    "print(perceptron.sign([5, 1]))\n",
    "print(perceptron.sign([5, 10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fed76d",
   "metadata": {},
   "source": [
    "### 1.1.2 –ü—Ä–∏–º–µ—Ä"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f76be9",
   "metadata": {},
   "source": [
    "–î–ª—è –Ω–∞–ø–∏—Å–∞–Ω–∏—è –∫–æ–¥–∞ –Ω–µ–π—Ä–æ–Ω–∞ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É Pytnon  \n",
    "‚Äî NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16d5f647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990889488055994\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    # –§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: f(x) = 1 / (1 + e^(-x))\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)\n",
    "    \n",
    "\n",
    "weights = np.array([0, 1]) # w1 = 0, w2 = 1\n",
    "bias = 4                   # c = 4\n",
    "n = Neuron(weights, bias)\n",
    "x = np.array([2, 3])\n",
    "print(n.feedforward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc29259",
   "metadata": {},
   "source": [
    "–ù–µ–π—Ä–æ—Å–µ—Ç—å —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –º–µ–∂–¥—É —Å–æ–±–æ–π –Ω–µ–π—Ä–æ–Ω–æ–≤.  \n",
    "–ü—Ä–∏–º–µ—Ä –Ω–µ—Å–ª–æ–∂–Ω–æ–π –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏\n",
    "![](wb7p1.jpg)\n",
    ">–≥–¥–µ:  \n",
    ">$ùë•_1, ùë•_2$ ‚Äî –≤—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π;  \n",
    ">$‚Ñé_1, ‚Ñé_2$ ‚Äî —Å–∫—Ä—ã—Ç—ã–π —Å–ª–æ–π —Å –¥–≤—É–º—è –Ω–µ–π—Ä–æ–Ω–∞–º–∏;  \n",
    ">$ùëú_1$ ‚Äî –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π.  \n",
    "\n",
    "–ù–∞–ø—Ä–∏–º–µ—Ä. –ü—Ä–µ–¥—Å—Ç–∞–≤–∏–º, —á—Ç–æ –Ω–µ–π—Ä–æ–Ω—ã –∏–∑ –≥—Ä–∞—Ñ–∏–∫–∞ –≤—ã—à–µ –∏–º–µ—é—Ç –≤–µ—Å–∞  \n",
    "[0, 1]. –ü–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (ùëè) —É –æ–±–æ–∏—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤ —Ä–∞–≤–Ω–æ 0 –∏ –æ–Ω–∏ –∏–º–µ—é—Ç  \n",
    "–∏–¥–µ–Ω—Ç–∏—á–Ω—É—é —Å–∏–≥–º–æ–∏–¥—É.  \n",
    "–ü—Ä–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö ùë• = [2, 3] –ø–æ–ª—É—á–∏–º:  \n",
    "\n",
    "‚Ñé1 = ‚Ñé2 = ùëì(ùë§ùë• + ùëè) = ùëì((02) + (1 ‚àó 3) + 0) = ùëì(3) = 0.95.  \n",
    "ùëú1 = ùëì(ùë§ ‚àó [‚Ñé1, ‚Ñé2] + ùëè) = ùëì((0‚Ñé1) + (1‚Ñé2) + 0) = ùëì(0.95) = 0.72.  \n",
    "\n",
    "–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ –Ω–µ–π—Ä–æ–Ω–∞–º –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è –¥–æ —Ç–µ—Ö –ø–æ—Ä, –ø–æ–∫–∞ –Ω–µ  \n",
    "–ø–æ–ª—É—á–∞—Ç—Å—è –≤—ã—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "662d217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7216325609518421\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class OurNeuralNetwork:\n",
    "    '''\n",
    "    –î–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:\n",
    "        - –¥–≤–∞ –≤—Ö–æ–¥–∞\n",
    "        - –¥–≤–∞ –Ω–µ–π—Ä–æ–Ω–∞ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö (h1, h2)\n",
    "        - –≤—ã—Ö–æ–¥ (o1)\n",
    "    –ù–µ–π—Ä–æ–Ω—ã –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –≤–µ—Å–∞ –∏ –ø–æ—Ä–æ–≥–∏:\n",
    "        - w = [0, 1]\n",
    "        - b = 0\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        weights = np.array([0, 1])\n",
    "        bias = 0\n",
    "        # –ö–ª–∞—Å—Å Neuron –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–¥–µ–ª–∞\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        # –í—Ö–æ–¥—ã –¥–ª—è o1 - —ç—Ç–æ –º–µ—Ç–æ–¥—ã h1 –∏ h2\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        return out_o1\n",
    "\n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2, 3])\n",
    "print(network.feedforward(x)) # 0.7216325609518421"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedc627e",
   "metadata": {},
   "source": [
    "### –ó–∞–¥–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0044898f",
   "metadata": {},
   "source": [
    "–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∫–ª–∞—Å—Å—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –ø–æ –∞–Ω–∞–ª–æ–≥–∏–∏ —Å –∫–ª–∞—Å—Å–æ–º OurNeuralNetwork.  \n",
    "–î–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:  \n",
    "- —Ç—Ä–∏ –≤—Ö–æ–¥–∞ (ùë•1, ùë•2, ùë•3);  \n",
    "- —Ç—Ä–∏ –Ω–µ–π—Ä–æ–Ω–∞ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö (‚Ñé1, ‚Ñé2, ‚Ñé3);  \n",
    "- –≤—ã—Ö–æ–¥ (ùëú1).  \n",
    "\n",
    "–ù–µ–π—Ä–æ–Ω—ã –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –≤–µ—Å–∞ –∏ –ø–æ—Ä–æ–≥–∏:  \n",
    "- ùë§ = [0.5, 0.5, 0.5]  \n",
    "- ùëè = 0  \n",
    "\n",
    "–î–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:  \n",
    "- –¥–≤–∞ –≤—Ö–æ–¥–∞ (ùë•1, ùë•2);  \n",
    "- –¥–≤–∞ –Ω–µ–π—Ä–æ–Ω–∞ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö (‚Ñé1, ‚Ñé2);  \n",
    "- –¥–≤–∞ –≤—ã—Ö–æ–¥–∞ (ùëú1, ùëú2).  \n",
    "\n",
    "–ù–µ–π—Ä–æ–Ω—ã –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –≤–µ—Å–∞ –∏ –ø–æ—Ä–æ–≥–∏:  \n",
    "- ùë§ = [1, 0];  \n",
    "- ùëè = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30029231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8067238139969796\n",
      "0.8757270529783324   0.8757270529783324\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    # –§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: f(x) = 1 / (1 + e^(-x))\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        \n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)\n",
    "    \n",
    "class OurNeuralNetwork1:\n",
    "    '''\n",
    "    –î–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:\n",
    "        - —Ç—Ä–∏ –≤—Ö–æ–¥–∞ (ùë•1, ùë•2, ùë•3);  \n",
    "        - —Ç—Ä–∏ –Ω–µ–π—Ä–æ–Ω–∞ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö (‚Ñé1, ‚Ñé2, ‚Ñé3);  \n",
    "        - –≤—ã—Ö–æ–¥ (ùëú1). \n",
    "    –ù–µ–π—Ä–æ–Ω—ã –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –≤–µ—Å–∞ –∏ –ø–æ—Ä–æ–≥–∏:\n",
    "        - ùë§ = [0.5, 0.5, 0.5]  \n",
    "        - ùëè = 0  \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5]) # ùë§ = [0.5, 0.5, 0.5]\n",
    "        bias = 0                            # b = 0\n",
    "\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.h3 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_h3 = self.h3.feedforward(x)\n",
    "        # –í—Ö–æ–¥—ã –¥–ª—è o1 - —ç—Ç–æ –º–µ—Ç–æ–¥—ã h1, h2 –∏ h3\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        return out_o1\n",
    "\n",
    " \n",
    "class OurNeuralNetwork2:\n",
    "    '''\n",
    "    –î–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:\n",
    "        - –¥–≤–∞ –≤—Ö–æ–¥–∞ (ùë•1, ùë•2);  \n",
    "        - –¥–≤–∞ –Ω–µ–π—Ä–æ–Ω–∞ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö (‚Ñé1, ‚Ñé2);  \n",
    "        - –¥–≤–∞ –≤—ã—Ö–æ–¥–∞ (ùëú1, ùëú2).  \n",
    "    –ù–µ–π—Ä–æ–Ω—ã –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –≤–µ—Å–∞ –∏ –ø–æ—Ä–æ–≥–∏:\n",
    "        - ùë§ = [1, 0];  \n",
    "        - ùëè = 1.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        weights = np.array([1, 0]) # ùë§ = [1, 0]\n",
    "        bias = 1                   # b = 1\n",
    "\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        self.o2 = Neuron(weights, bias)\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        # –í—Ö–æ–¥—ã –¥–ª—è o1 - —ç—Ç–æ –º–µ—Ç–æ–¥—ã h1, h2 –∏ h3\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        out_o2 = self.o2.feedforward(np.array([out_h2, out_h2]))\n",
    "        return \"{}   {}\".format(out_o1, out_o2)\n",
    "\n",
    "\n",
    "network1 = OurNeuralNetwork1()\n",
    "network2 = OurNeuralNetwork2()\n",
    "\n",
    "x1 = np.array([2, 3, 1])\n",
    "x2 = np.array([2, 3])\n",
    "\n",
    "print(network1.feedforward(x1)) # 0.8067238139969796\n",
    "print(network2.feedforward(x2)) # 0.8757270529783324   0.8757270529783324"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5fb0f3",
   "metadata": {},
   "source": [
    "### –ó–∞–¥–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7718e0f",
   "metadata": {},
   "source": [
    "–†–µ–∞–ª–∏–∑—É–π—Ç–µ –∫–ª–∞—Å—Å—ã –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥—Ä—É–≥–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π  \n",
    "–∞–∫—Ç–∏–≤–∞—Ü–∏–∏.\n",
    "![](wb7p2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25dbc074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used sigmoid 0.7216325609518421\n",
      "Used tanh 0.903798759264991\n",
      "Used ReLU 4   4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    # –§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: f(x) = 1 / (1 + e^(-x))\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    # –§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: f(x) = tanh(X)\n",
    "    return np.tanh(x)\n",
    "\n",
    "def ReLU(x):\n",
    "    # –§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: f(x) = max(0, x)\n",
    "    return max(0, x)\n",
    "\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)\n",
    "\n",
    "class Neuron1:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return tanh(total)\n",
    "    \n",
    "class Neuron2:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return ReLU(total)\n",
    "\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "    '''\n",
    "    –î–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:\n",
    "        - –¥–≤–∞ –≤—Ö–æ–¥–∞\n",
    "        - –¥–≤–∞ –Ω–µ–π—Ä–æ–Ω–∞ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö (h1, h2)\n",
    "        - –≤—ã—Ö–æ–¥ (o1)\n",
    "    –ù–µ–π—Ä–æ–Ω—ã –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –≤–µ—Å–∞ –∏ –ø–æ—Ä–æ–≥–∏:\n",
    "        - w = [0, 1]\n",
    "        - b = 0\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        weights = np.array([0, 1])\n",
    "        bias = 0\n",
    "        # –ö–ª–∞—Å—Å Neuron –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–¥–µ–ª–∞\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        # –í—Ö–æ–¥—ã –¥–ª—è o1 - —ç—Ç–æ –º–µ—Ç–æ–¥—ã h1 –∏ h2\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        return out_o1\n",
    "\n",
    "class OurNeuralNetwork1:\n",
    "    '''\n",
    "    –î–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:\n",
    "        - —Ç—Ä–∏ –≤—Ö–æ–¥–∞ (ùë•1, ùë•2, ùë•3);  \n",
    "        - —Ç—Ä–∏ –Ω–µ–π—Ä–æ–Ω–∞ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö (‚Ñé1, ‚Ñé2, ‚Ñé3);  \n",
    "        - –≤—ã—Ö–æ–¥ (ùëú1). \n",
    "    –ù–µ–π—Ä–æ–Ω—ã –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –≤–µ—Å–∞ –∏ –ø–æ—Ä–æ–≥–∏:\n",
    "        - ùë§ = [0.5, 0.5, 0.5]  \n",
    "        - ùëè = 0  \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5]) # ùë§ = [0.5, 0.5, 0.5]\n",
    "        bias = 0                            # b = 0\n",
    "\n",
    "        self.h1 = Neuron1(weights, bias)\n",
    "        self.h2 = Neuron1(weights, bias)\n",
    "        self.h3 = Neuron1(weights, bias)\n",
    "        self.o1 = Neuron1(weights, bias)\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h1.feedforward(x)\n",
    "        out_h3 = self.h1.feedforward(x)\n",
    "        # –í—Ö–æ–¥—ã –¥–ª—è o1 - —ç—Ç–æ –º–µ—Ç–æ–¥—ã h1, h2 –∏ h3\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        return out_o1\n",
    "\n",
    " \n",
    "class OurNeuralNetwork2:\n",
    "    '''\n",
    "    –î–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:\n",
    "        - –¥–≤–∞ –≤—Ö–æ–¥–∞ (ùë•1, ùë•2);  \n",
    "        - –¥–≤–∞ –Ω–µ–π—Ä–æ–Ω–∞ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö (‚Ñé1, ‚Ñé2);  \n",
    "        - –¥–≤–∞ –≤—ã—Ö–æ–¥–∞ (ùëú1, ùëú2).  \n",
    "    –ù–µ–π—Ä–æ–Ω—ã –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –≤–µ—Å–∞ –∏ –ø–æ—Ä–æ–≥–∏:\n",
    "        - ùë§ = [1, 0];  \n",
    "        - ùëè = 1.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        weights = np.array([1, 0]) # ùë§ = [1, 0]\n",
    "        bias = 1                   # b = 1\n",
    "\n",
    "        self.h1 = Neuron2(weights, bias)\n",
    "        self.h2 = Neuron2(weights, bias)\n",
    "        self.o1 = Neuron2(weights, bias)\n",
    "        self.o2 = Neuron2(weights, bias)\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h1.feedforward(x)\n",
    "        # –í—Ö–æ–¥—ã –¥–ª—è o1 - —ç—Ç–æ –º–µ—Ç–æ–¥—ã h1, h2 –∏ h3\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        out_o2 = self.o2.feedforward(np.array([out_h2, out_h2]))\n",
    "        return \"{}   {}\".format(out_o1, out_o2)\n",
    "    \n",
    "    \n",
    "network = OurNeuralNetwork()\n",
    "network1 = OurNeuralNetwork1()\n",
    "network2 = OurNeuralNetwork2()\n",
    "\n",
    "x = np.array([2, 3])\n",
    "x1 = np.array([2, 3, 1])\n",
    "x2 = np.array([2, 3])\n",
    "\n",
    "\n",
    "print('Used sigmoid', network.feedforward(x)) # 0.7216325609518421\n",
    "print('Used tanh', network1.feedforward(x1)) # 0.903798759264991\n",
    "print('Used ReLU', network2.feedforward(x2)) # 4   4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4ce5d7",
   "metadata": {},
   "source": [
    "### –ó–∞–¥–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b1a4b7",
   "metadata": {},
   "source": [
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–ª–∞—Å—Å—ã MLPClassified –∏ MLPRegressor –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏  \n",
    "—Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞. –ü—Ä–æ–≤–µ–¥–∏—Ç–µ –∞–Ω–∞–ª–∏–∑  \n",
    "–∞—Ç—Ä–∏–±—É—Ç—ã, –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.  \n",
    "\n",
    "–î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –º–æ–∂–µ—Ç–µ –≤–∑—è—Ç—å –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ò—Ä–∏—Å–æ–≤:  \n",
    "https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv  \n",
    "–∞ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∑–∞—Ä–∞–±–æ—Ç–Ω–æ–π –ø–ª–∞—Ç—ã –æ—Ç –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã:\n",
    "https://raw.githubusercontent.com/AnnaShestova/salary-years-simple-linear-regression/master/Salary_Data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59e7460f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Versicolor' 'Setosa' 'Virginica' 'Virginica' 'Setosa' 'Setosa'\n",
      " 'Virginica' 'Virginica' 'Virginica' 'Setosa' 'Setosa' 'Versicolor'\n",
      " 'Virginica' 'Versicolor' 'Virginica' 'Versicolor' 'Setosa' 'Setosa'\n",
      " 'Setosa' 'Setosa' 'Setosa' 'Virginica' 'Virginica' 'Versicolor'\n",
      " 'Virginica' 'Virginica' 'Versicolor' 'Versicolor' 'Virginica'\n",
      " 'Versicolor']\n",
      "['Versicolor' 'Setosa' 'Virginica' 'Virginica' 'Setosa' 'Setosa'\n",
      " 'Virginica' 'Versicolor' 'Virginica' 'Setosa' 'Setosa' 'Versicolor'\n",
      " 'Virginica' 'Versicolor' 'Virginica' 'Versicolor' 'Setosa' 'Setosa'\n",
      " 'Setosa' 'Setosa' 'Setosa' 'Virginica' 'Virginica' 'Versicolor'\n",
      " 'Virginica' 'Virginica' 'Versicolor' 'Versicolor' 'Versicolor'\n",
      " 'Versicolor']\n",
      "Test Accuracy: 0.933\n",
      "Traiding Accuracy: 0.983\n",
      "Loss:  0.2988789340197433\n",
      "Number of Coefs:  2\n",
      "Number of Intercepts:  2\n",
      "Number of Iterations for Which Estimator Ran: 200\n",
      "Name of Output Layer Activation Function:  softmax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "url = \"https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.80, test_size=0.20,\n",
    "                                                    stratify=y, random_state=123)\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ MLPClassifier\n",
    "clf = MLPClassifier(random_state=123)\n",
    "\n",
    "# MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "#              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "#              hidden_layer_sizes=(100, ), learning_rate='constant',\n",
    "#              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
    "#              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
    "#              validation_fraction=0.1, verbose=False, warm_start=False)\n",
    "\n",
    "# # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "print('Test Accuracy: %.3f'%clf.score(X_test, y_test))\n",
    "print('Traiding Accuracy: %.3f'%clf.score(X_train, y_train))\n",
    "print('Loss: ', clf.loss_)\n",
    "print('Number of Coefs: ', len(clf.coefs_))\n",
    "print('Number of Intercepts: ', len(clf.intercepts_))\n",
    "print('Number of Iterations for Which Estimator Ran:', clf.n_iter_)\n",
    "print('Name of Output Layer Activation Function: ', clf.out_activation_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "684873de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20.26234628 55.2781752  18.82135812 50.48274487 20.26234628 50.9622879 ]\n",
      "[ 54445. 121872.  56642. 116969.  64445. 112635.]\n",
      "Test R^2 Score: -8.796\n",
      "Traiding R^2 Score: -8.261\n",
      "Loss:  2988058032.1601596\n",
      "Number of Coefs:  2\n",
      "Number of Intercepts:  2\n",
      "Number of Iterations for Which Estimator Ran: 200\n",
      "Name of Output Layer Activation Function:  identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "url = \"https://raw.githubusercontent.com/AnnaShestova/salary-years-simple-linear-regression/master/Salary_Data.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.80, test_size=0.20,\n",
    "                                                    random_state=123)\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ MLPClassifier\n",
    "reg = MLPRegressor(random_state=123)\n",
    "# reg = MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "#              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "#              hidden_layer_sizes=(100, ), learning_rate='constant',\n",
    "#              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
    "#              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
    "#              random_state=123, shuffle=True, solver='adam', tol=0.0001,\n",
    "#              validation_fraction=0.1, verbose=False, warm_start=False)\n",
    "\n",
    "# MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "#              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "#              hidden_layer_sizes=(100, ), learning_rate='constant',\n",
    "#              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
    "#              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
    "#              random_state=123, shuffle=True, solver='adam', tol=0.0001,\n",
    "#              validation_fraction=0.1, verbose=False, warm_start=False)\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "print('Test R^2 Score: %.3f'%reg.score(X_test, y_test))\n",
    "print('Traiding R^2 Score: %.3f'%reg.score(X_train, y_train))\n",
    "print('Loss: ', reg.loss_)\n",
    "print('Number of Coefs: ', len(reg.coefs_))\n",
    "print('Number of Intercepts: ', len(reg.intercepts_))\n",
    "print('Number of Iterations for Which Estimator Ran:', reg.n_iter_)\n",
    "print('Name of Output Layer Activation Function: ', reg.out_activation_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
